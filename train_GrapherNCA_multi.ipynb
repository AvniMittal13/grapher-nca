{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med-GrapherNCA: Multi-Level Experiments\n",
    "### All 6 combinations: b1b1, m1b1, m1m1, m2b1, m2m2, m1m2\n",
    "\n",
    "This notebook trains multi-level (2-level) model combinations on the ISIC 2018 dataset.\n",
    "Level 0 operates on 64x64 downsampled images, Level 1 operates on 256x256 patches.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Colab Setup: Mount Drive & Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup project directory in Google Drive\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Experiments/Grapher_NCA'\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, 'datasets', 'ISIC2018')\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, 'Models')\n",
    "\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Dataset dir:  {DATASET_DIR}')\n",
    "print(f'Models dir:   {MODELS_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DATASET_DIR\"\n",
    "DATASET_DIR=$1\n",
    "\n",
    "# Download ISIC 2018 Task 1 Training Data (images + masks)\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1-2_Training_Input\" ]; then\n",
    "    echo \"Downloading ISIC 2018 training images...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/train_input.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1-2_Training_Input.zip\"\n",
    "    echo \"Extracting training images...\"\n",
    "    unzip -q \"$DATASET_DIR/train_input.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/train_input.zip\"\n",
    "else\n",
    "    echo \"Training images already exist, skipping download.\"\n",
    "fi\n",
    "\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1_Training_GroundTruth\" ]; then\n",
    "    echo \"Downloading ISIC 2018 training ground truth...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/train_gt.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1_Training_GroundTruth.zip\"\n",
    "    echo \"Extracting training ground truth...\"\n",
    "    unzip -q \"$DATASET_DIR/train_gt.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/train_gt.zip\"\n",
    "else\n",
    "    echo \"Training ground truth already exists, skipping download.\"\n",
    "fi\n",
    "\n",
    "# Download ISIC 2018 Task 1 Test Data (images + masks)\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1-2_Test_Input\" ]; then\n",
    "    echo \"Downloading ISIC 2018 test images...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/test_input.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1-2_Test_Input.zip\"\n",
    "    echo \"Extracting test images...\"\n",
    "    unzip -q \"$DATASET_DIR/test_input.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/test_input.zip\"\n",
    "else\n",
    "    echo \"Test images already exist, skipping download.\"\n",
    "fi\n",
    "\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1_Test_GroundTruth\" ]; then\n",
    "    echo \"Downloading ISIC 2018 test ground truth...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/test_gt.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1_Test_GroundTruth.zip\"\n",
    "    echo \"Extracting test ground truth...\"\n",
    "    unzip -q \"$DATASET_DIR/test_gt.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/test_gt.zip\"\n",
    "else\n",
    "    echo \"Test ground truth already exists, skipping download.\"\n",
    "fi\n",
    "\n",
    "echo \"\\nDataset contents:\"\n",
    "ls -la \"$DATASET_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, sys\n\n# Clone repo from GitHub into Colab's /content (fast, always fresh)\nREPO_DIR = '/content/grapher-nca/M3D-NCA'\nif not os.path.isdir('/content/grapher-nca'):\n    os.system('git clone https://github.com/AvniMittal13/grapher-nca.git /content/grapher-nca')\n\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\n# Install dependencies\nos.system('pip install -q torchio==0.18.82 nibabel tensorboard')\n\nprint(f'Repo dir: {REPO_DIR}')\nprint(f'sys.path OK: {REPO_DIR in sys.path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.datasets.ISIC_Dataset import ISIC2018_Dataset\n",
    "from src.models.Model_BackboneNCA import BackboneNCA\n",
    "from src.models.Model_GrapherNCA_M1 import GrapherNCA_M1\n",
    "from src.models.Model_GrapherNCA_M2 import GrapherNCA_M2\n",
    "from src.losses.LossFunctions import DiceLoss\n",
    "from src.utils.Experiment import Experiment\n",
    "from src.agents.Agent_Med_NCA import Agent_Med_NCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Experiment\n",
    "\n",
    "Choose a combination to train:\n",
    "- `'b1b1'` — BackboneNCA + BackboneNCA\n",
    "- `'m1b1'` — Pixel-Grapher + BackboneNCA  \n",
    "- `'m1m1'` — Pixel-Grapher + Pixel-Grapher\n",
    "- `'m2b1'` — Patch-Grapher + BackboneNCA\n",
    "- `'m2m2'` — Patch-Grapher + Patch-Grapher\n",
    "- `'m1m2'` — Pixel-Grapher + Patch-Grapher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose multi-level combination\n",
    "combination = 'm1b1'\n",
    "\n",
    "config = [{\n",
    "    'img_path': os.path.join(DATASET_DIR, 'ISIC2018_Task1-2_Training_Input'),\n",
    "    'label_path': os.path.join(DATASET_DIR, 'ISIC2018_Task1_Training_GroundTruth'),\n",
    "    'model_path': os.path.join(MODELS_DIR, f'GrapherNCA_multi_{combination}'),\n",
    "    'device': 'cuda:0',\n",
    "    'unlock_CPU': True,\n",
    "    # Optimizer\n",
    "    'lr': 1e-4,\n",
    "    'lr_gamma': 0.9999,\n",
    "    'betas': (0.5, 0.5),\n",
    "    # Training\n",
    "    'save_interval': 10,\n",
    "    'evaluate_interval': 10,\n",
    "    'n_epoch': 1000,\n",
    "    'batch_size': 8,\n",
    "    # Model\n",
    "    'channel_n': 64,\n",
    "    'inference_steps': 10,\n",
    "    'cell_fire_rate': 0.5,\n",
    "    'input_channels': 3,\n",
    "    'output_channels': 1,\n",
    "    'hidden_size': 512,\n",
    "    'train_model': 1,  # Multi-level: train both levels\n",
    "    # Data\n",
    "    'input_size': [(64, 64), (256, 256)],\n",
    "    'data_split': [0.7, 0, 0.3],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_code, config, device):\n",
    "    \"\"\"Create a model instance from a code string.\"\"\"\n",
    "    if model_code == 'b1':\n",
    "        return BackboneNCA(\n",
    "            config['channel_n'], config['cell_fire_rate'], device,\n",
    "            hidden_size=config['hidden_size'], input_channels=config['input_channels']\n",
    "        ).to(device)\n",
    "    elif model_code == 'm1':\n",
    "        return GrapherNCA_M1(\n",
    "            config['channel_n'], config['cell_fire_rate'], device,\n",
    "            hidden_size=config['hidden_size'], input_channels=config['input_channels'],\n",
    "            k=9\n",
    "        ).to(device)\n",
    "    elif model_code == 'm2':\n",
    "        return GrapherNCA_M2(\n",
    "            config['channel_n'], config['cell_fire_rate'], device,\n",
    "            hidden_size=config['hidden_size'], input_channels=config['input_channels'],\n",
    "            k=9, patch_size=4\n",
    "        ).to(device)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model code: {model_code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISIC2018_Dataset(input_channels=config[0]['input_channels'])\n",
    "device = torch.device(config[0]['device'])\n",
    "\n",
    "# Parse combination: first 2 chars = level 0, last 2 chars = level 1\n",
    "level0_code = combination[:2]\n",
    "level1_code = combination[2:]\n",
    "\n",
    "ca1 = create_model(level0_code, config[0], device)  # Downsampled level\n",
    "ca2 = create_model(level1_code, config[0], device)  # Full resolution level\n",
    "ca = [ca1, ca2]\n",
    "\n",
    "agent = Agent_Med_NCA(ca)\n",
    "exp = Experiment(config, dataset, ca, agent)\n",
    "dataset.set_experiment(exp)\n",
    "exp.set_model_state('train')\n",
    "data_loader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=exp.get_from_config('batch_size'))\n",
    "\n",
    "loss_function = DiceLoss()\n",
    "\n",
    "# Print model info\n",
    "for i, m in enumerate(ca):\n",
    "    params = sum(p.numel() for p in m.parameters())\n",
    "    print(f'Level {i} ({[level0_code, level1_code][i]}): {params} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train(data_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.getAverageDiceScore(pseudo_ensemble=True, showResults=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}