{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med-GrapherNCA: Evaluation & Comparison\n",
    "### Dice, IoU, Pseudo-Ensemble Variance across all configurations\n",
    "\n",
    "This notebook loads trained models and evaluates them on the ISIC 2018 test set.\n",
    "It reproduces Tables 1-3 from the paper.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Colab Setup: Mount Drive & Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup project directory in Google Drive\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Experiments/Grapher_NCA'\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, 'datasets', 'ISIC2018')\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, 'Models')\n",
    "\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Dataset dir:  {DATASET_DIR}')\n",
    "print(f'Models dir:   {MODELS_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DATASET_DIR\"\n",
    "DATASET_DIR=$1\n",
    "\n",
    "# Download ISIC 2018 Task 1 Training Data (images + masks)\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1-2_Training_Input\" ]; then\n",
    "    echo \"Downloading ISIC 2018 training images...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/train_input.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1-2_Training_Input.zip\"\n",
    "    echo \"Extracting training images...\"\n",
    "    unzip -q \"$DATASET_DIR/train_input.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/train_input.zip\"\n",
    "else\n",
    "    echo \"Training images already exist, skipping download.\"\n",
    "fi\n",
    "\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1_Training_GroundTruth\" ]; then\n",
    "    echo \"Downloading ISIC 2018 training ground truth...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/train_gt.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1_Training_GroundTruth.zip\"\n",
    "    echo \"Extracting training ground truth...\"\n",
    "    unzip -q \"$DATASET_DIR/train_gt.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/train_gt.zip\"\n",
    "else\n",
    "    echo \"Training ground truth already exists, skipping download.\"\n",
    "fi\n",
    "\n",
    "# Download ISIC 2018 Task 1 Test Data (images + masks)\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1-2_Test_Input\" ]; then\n",
    "    echo \"Downloading ISIC 2018 test images...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/test_input.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1-2_Test_Input.zip\"\n",
    "    echo \"Extracting test images...\"\n",
    "    unzip -q \"$DATASET_DIR/test_input.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/test_input.zip\"\n",
    "else\n",
    "    echo \"Test images already exist, skipping download.\"\n",
    "fi\n",
    "\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1_Test_GroundTruth\" ]; then\n",
    "    echo \"Downloading ISIC 2018 test ground truth...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/test_gt.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1_Test_GroundTruth.zip\"\n",
    "    echo \"Extracting test ground truth...\"\n",
    "    unzip -q \"$DATASET_DIR/test_gt.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/test_gt.zip\"\n",
    "else\n",
    "    echo \"Test ground truth already exists, skipping download.\"\n",
    "fi\n",
    "\n",
    "echo \"\\nDataset contents:\"\n",
    "ls -la \"$DATASET_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, sys\n\n# Clone repo from GitHub into Colab's /content (fast, always fresh)\nREPO_DIR = '/content/grapher-nca/M3D-NCA'\nif not os.path.isdir('/content/grapher-nca'):\n    os.system('git clone https://github.com/AvniMittal13/grapher-nca.git /content/grapher-nca')\nelse:\n    os.system('git -C /content/grapher-nca pull')\n\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\n# Install dependencies\nos.system('pip install -q torchio==0.18.82 nibabel tensorboard')\n\nprint(f'Repo dir: {REPO_DIR}')\nprint(f'sys.path OK: {REPO_DIR in sys.path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.datasets.ISIC_Dataset import ISIC2018_Dataset\n",
    "from src.models.Model_BackboneNCA import BackboneNCA\n",
    "from src.models.Model_GrapherNCA_M1 import GrapherNCA_M1\n",
    "from src.models.Model_GrapherNCA_M2 import GrapherNCA_M2\n",
    "from src.losses.LossFunctions import DiceLoss, IoULoss\n",
    "from src.utils.Experiment import Experiment\n",
    "from src.agents.Agent_Med_NCA import Agent_Med_NCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_code, config, device):\n",
    "    \"\"\"Create a model instance from a code string.\"\"\"\n",
    "    if model_code == 'b1':\n",
    "        return BackboneNCA(\n",
    "            config['channel_n'], config['cell_fire_rate'], device,\n",
    "            hidden_size=config['hidden_size'], input_channels=config['input_channels']\n",
    "        ).to(device)\n",
    "    elif model_code == 'm1':\n",
    "        return GrapherNCA_M1(\n",
    "            config['channel_n'], config['cell_fire_rate'], device,\n",
    "            hidden_size=config['hidden_size'], input_channels=config['input_channels'],\n",
    "            k=9\n",
    "        ).to(device)\n",
    "    elif model_code == 'm2':\n",
    "        return GrapherNCA_M2(\n",
    "            config['channel_n'], config['cell_fire_rate'], device,\n",
    "            hidden_size=config['hidden_size'], input_channels=config['input_channels'],\n",
    "            k=9, patch_size=4\n",
    "        ).to(device)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model code: {model_code}')\n",
    "\n",
    "\n",
    "def compute_metrics(agent, useSigmoid=True):\n",
    "    \"\"\"Compute Dice and IoU on the test set.\"\"\"\n",
    "    dice_loss_fn = DiceLoss(useSigmoid=useSigmoid)\n",
    "    iou_loss_fn = IoULoss(useSigmoid=useSigmoid)\n",
    "\n",
    "    dataset = agent.exp.dataset\n",
    "    agent.exp.set_model_state('test')\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            data = agent.prepare_data(data, eval=True)\n",
    "            outputs, targets = agent.get_outputs(data, full_img=True, tag='eval')\n",
    "            dice = 1 - dice_loss_fn(outputs[..., 0], targets[..., 0], smooth=0).item()\n",
    "            iou = 1 - iou_loss_fn(outputs[..., 0], targets[..., 0], smooth=0).item()\n",
    "            dice_scores.append(dice)\n",
    "            iou_scores.append(iou)\n",
    "\n",
    "    agent.exp.set_model_state('train')\n",
    "    return {\n",
    "        'dice_mean': np.mean(dice_scores),\n",
    "        'dice_std': np.std(dice_scores),\n",
    "        'iou_mean': np.mean(iou_scores),\n",
    "        'iou_std': np.std(iou_scores),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "base_config = {\n",
    "    'img_path': os.path.join(DATASET_DIR, 'ISIC2018_Task1-2_Training_Input'),\n",
    "    'label_path': os.path.join(DATASET_DIR, 'ISIC2018_Task1_Training_GroundTruth'),\n",
    "    'device': str(device),\n",
    "    'unlock_CPU': True,\n",
    "    'lr': 1e-4,\n",
    "    'lr_gamma': 0.9999,\n",
    "    'betas': (0.5, 0.5),\n",
    "    'save_interval': 10,\n",
    "    'evaluate_interval': 10,\n",
    "    'n_epoch': 1000,\n",
    "    'batch_size': 8,\n",
    "    'channel_n': 64,\n",
    "    'inference_steps': 10,\n",
    "    'cell_fire_rate': 0.5,\n",
    "    'input_channels': 3,\n",
    "    'output_channels': 1,\n",
    "    'hidden_size': 512,\n",
    "    'data_split': [0.7, 0, 0.3],\n",
    "}\n",
    "\n",
    "# Single-level experiments\n",
    "single_experiments = ['b1', 'm1', 'm2']\n",
    "\n",
    "# Multi-level experiments\n",
    "multi_experiments = ['b1b1', 'm1b1', 'm1m1', 'm2b1', 'm2m2', 'm1m2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Single-Level Models (Table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_results = {}\n",
    "\n",
    "for model_type in single_experiments:\n",
    "    print(f'\\n=== Evaluating single-level: {model_type} ===')\n",
    "    config = base_config.copy()\n",
    "    config['model_path'] = os.path.join(MODELS_DIR, f'GrapherNCA_single_{model_type}')\n",
    "    config['input_size'] = [(256, 256)]\n",
    "    config['train_model'] = 0\n",
    "\n",
    "    dataset = ISIC2018_Dataset(input_channels=config['input_channels'])\n",
    "    ca = [create_model(model_type, config, device)]\n",
    "    agent = Agent_Med_NCA(ca)\n",
    "    exp = Experiment([config], dataset, ca, agent)\n",
    "    dataset.set_experiment(exp)\n",
    "\n",
    "    metrics = compute_metrics(agent)\n",
    "    single_results[model_type] = metrics\n",
    "\n",
    "    params = sum(p.numel() for p in ca[0].parameters())\n",
    "    print(f'  Params: {params}')\n",
    "    print(f'  Dice: {metrics[\"dice_mean\"]:.4f} +/- {metrics[\"dice_std\"]:.4f}')\n",
    "    print(f'  IoU:  {metrics[\"iou_mean\"]:.4f} +/- {metrics[\"iou_std\"]:.4f}')\n",
    "\n",
    "# Display as table\n",
    "df_single = pd.DataFrame(single_results).T\n",
    "df_single.columns = ['Dice (mean)', 'Dice (std)', 'IoU (mean)', 'IoU (std)']\n",
    "print('\\n--- Table 2: Single-Level Results ---')\n",
    "print(df_single.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Multi-Level Models (Table 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_results = {}\n",
    "\n",
    "for combination in multi_experiments:\n",
    "    print(f'\\n=== Evaluating multi-level: {combination} ===')\n",
    "    config = base_config.copy()\n",
    "    config['model_path'] = os.path.join(MODELS_DIR, f'GrapherNCA_multi_{combination}')\n",
    "    config['input_size'] = [(64, 64), (256, 256)]\n",
    "    config['train_model'] = 1\n",
    "\n",
    "    dataset = ISIC2018_Dataset(input_channels=config['input_channels'])\n",
    "    level0_code = combination[:2]\n",
    "    level1_code = combination[2:]\n",
    "    ca1 = create_model(level0_code, config, device)\n",
    "    ca2 = create_model(level1_code, config, device)\n",
    "    ca = [ca1, ca2]\n",
    "\n",
    "    agent = Agent_Med_NCA(ca)\n",
    "    exp = Experiment([config], dataset, ca, agent)\n",
    "    dataset.set_experiment(exp)\n",
    "\n",
    "    metrics = compute_metrics(agent)\n",
    "    multi_results[combination] = metrics\n",
    "\n",
    "    total_params = sum(p.numel() for m in ca for p in m.parameters())\n",
    "    print(f'  Total Params: {total_params}')\n",
    "    print(f'  Dice: {metrics[\"dice_mean\"]:.4f} +/- {metrics[\"dice_std\"]:.4f}')\n",
    "    print(f'  IoU:  {metrics[\"iou_mean\"]:.4f} +/- {metrics[\"iou_std\"]:.4f}')\n",
    "\n",
    "# Display as table\n",
    "df_multi = pd.DataFrame(multi_results).T\n",
    "df_multi.columns = ['Dice (mean)', 'Dice (std)', 'IoU (mean)', 'IoU (std)']\n",
    "print('\\n--- Table 3: Multi-Level Results ---')\n",
    "print(df_multi.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pseudo-Ensemble Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pseudo-ensemble on the best multi-level model\n",
    "combination = 'm1b1'\n",
    "\n",
    "config = base_config.copy()\n",
    "config['model_path'] = os.path.join(MODELS_DIR, f'GrapherNCA_multi_{combination}')\n",
    "config['input_size'] = [(64, 64), (256, 256)]\n",
    "config['train_model'] = 1\n",
    "\n",
    "dataset = ISIC2018_Dataset(input_channels=config['input_channels'])\n",
    "level0_code = combination[:2]\n",
    "level1_code = combination[2:]\n",
    "ca1 = create_model(level0_code, config, device)\n",
    "ca2 = create_model(level1_code, config, device)\n",
    "ca = [ca1, ca2]\n",
    "\n",
    "agent = Agent_Med_NCA(ca)\n",
    "exp = Experiment([config], dataset, ca, agent)\n",
    "dataset.set_experiment(exp)\n",
    "\n",
    "print(f'Pseudo-ensemble evaluation for {combination}:')\n",
    "agent.getAverageDiceScore(pseudo_ensemble=True, showResults=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization: Input / Prediction / Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(agent, sample_indices=[0, 5, 10], n_passes=10):\n",
    "    \"\"\"Visualize input, prediction, and variance map for selected samples.\"\"\"\n",
    "    dataset = agent.exp.dataset\n",
    "    agent.exp.set_model_state('test')\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            if i not in sample_indices:\n",
    "                continue\n",
    "            data = agent.prepare_data(data, eval=True)\n",
    "            data_id, inputs, targets = data\n",
    "\n",
    "            # Multiple forward passes for variance\n",
    "            preds = []\n",
    "            for _ in range(n_passes):\n",
    "                outputs, _ = agent.get_outputs(data, full_img=True, tag='viz')\n",
    "                preds.append(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "            preds = np.stack(preds, axis=0)\n",
    "            mean_pred = np.mean(preds, axis=0)\n",
    "            variance = np.std(preds, axis=0)\n",
    "\n",
    "            # Plot\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "            # Input image\n",
    "            inp = inputs[0].detach().cpu().numpy()\n",
    "            if inp.shape[-1] >= 3:\n",
    "                axes[0].imshow(inp[..., :3])\n",
    "            else:\n",
    "                axes[0].imshow(inp[..., 0], cmap='gray')\n",
    "            axes[0].set_title('Input')\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            # Ground truth\n",
    "            axes[1].imshow(targets[0, ..., 0].detach().cpu().numpy(), cmap='gray')\n",
    "            axes[1].set_title('Ground Truth')\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            # Mean prediction\n",
    "            axes[2].imshow(mean_pred[0, ..., 0], cmap='Purples')\n",
    "            axes[2].set_title('Mean Prediction')\n",
    "            axes[2].axis('off')\n",
    "\n",
    "            # Variance map\n",
    "            im = axes[3].imshow(variance[0, ..., 0], cmap='hot')\n",
    "            axes[3].set_title('Variance Map')\n",
    "            axes[3].axis('off')\n",
    "            plt.colorbar(im, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "            plt.suptitle(f'Sample {i}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    agent.exp.set_model_state('train')\n",
    "\n",
    "\n",
    "visualize_samples(agent, sample_indices=[0, 5, 10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Table (Table 1: Parameter Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter counts for all model types\n",
    "param_table = {}\n",
    "cfg = base_config.copy()\n",
    "\n",
    "for code in ['b1', 'm1', 'm2']:\n",
    "    m = create_model(code, cfg, device)\n",
    "    param_table[code] = sum(p.numel() for p in m.parameters())\n",
    "    del m\n",
    "\n",
    "print('--- Table 1: Parameter Counts ---')\n",
    "for code, count in param_table.items():\n",
    "    size_kb = count * 4 / 1024  # float32 = 4 bytes\n",
    "    print(f'{code}: {count:,} params ({size_kb:.1f} KB)')\n",
    "\n",
    "print('\\n--- Multi-level totals ---')\n",
    "for combo in multi_experiments:\n",
    "    l0, l1 = combo[:2], combo[2:]\n",
    "    total = param_table[l0] + param_table[l1]\n",
    "    size_kb = total * 4 / 1024\n",
    "    print(f'{combo}: {total:,} params ({size_kb:.1f} KB)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}