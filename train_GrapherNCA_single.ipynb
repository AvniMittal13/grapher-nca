{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Med-GrapherNCA: Single-Level Experiments\n",
    "### Pixel-Grapher-NCA (m1), Patch-Grapher-NCA (m2), Baseline BackboneNCA (b1)\n",
    "\n",
    "This notebook trains and evaluates individual models at a single resolution level on the ISIC 2018 dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Colab Setup: Mount Drive & Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup project directory in Google Drive\n",
    "PROJECT_ROOT = '/content/drive/MyDrive/Experiments/Grapher_NCA'\n",
    "DATASET_DIR = os.path.join(PROJECT_ROOT, 'datasets', 'ISIC2018')\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, 'Models')\n",
    "\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Dataset dir:  {DATASET_DIR}')\n",
    "print(f'Models dir:   {MODELS_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DATASET_DIR\"\n",
    "DATASET_DIR=$1\n",
    "\n",
    "# Download ISIC 2018 Task 1 Training Data (images + masks)\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1-2_Training_Input\" ]; then\n",
    "    echo \"Downloading ISIC 2018 training images...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/train_input.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1-2_Training_Input.zip\"\n",
    "    echo \"Extracting training images...\"\n",
    "    unzip -q \"$DATASET_DIR/train_input.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/train_input.zip\"\n",
    "else\n",
    "    echo \"Training images already exist, skipping download.\"\n",
    "fi\n",
    "\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1_Training_GroundTruth\" ]; then\n",
    "    echo \"Downloading ISIC 2018 training ground truth...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/train_gt.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1_Training_GroundTruth.zip\"\n",
    "    echo \"Extracting training ground truth...\"\n",
    "    unzip -q \"$DATASET_DIR/train_gt.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/train_gt.zip\"\n",
    "else\n",
    "    echo \"Training ground truth already exists, skipping download.\"\n",
    "fi\n",
    "\n",
    "# Download ISIC 2018 Task 1 Test Data (images + masks)\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1-2_Test_Input\" ]; then\n",
    "    echo \"Downloading ISIC 2018 test images...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/test_input.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1-2_Test_Input.zip\"\n",
    "    echo \"Extracting test images...\"\n",
    "    unzip -q \"$DATASET_DIR/test_input.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/test_input.zip\"\n",
    "else\n",
    "    echo \"Test images already exist, skipping download.\"\n",
    "fi\n",
    "\n",
    "if [ ! -d \"$DATASET_DIR/ISIC2018_Task1_Test_GroundTruth\" ]; then\n",
    "    echo \"Downloading ISIC 2018 test ground truth...\"\n",
    "    wget -q --show-progress -O \"$DATASET_DIR/test_gt.zip\" \\\n",
    "        \"https://isic-archive.s3.amazonaws.com/challenges/2018/ISIC2018_Task1_Test_GroundTruth.zip\"\n",
    "    echo \"Extracting test ground truth...\"\n",
    "    unzip -q \"$DATASET_DIR/test_gt.zip\" -d \"$DATASET_DIR\"\n",
    "    rm \"$DATASET_DIR/test_gt.zip\"\n",
    "else\n",
    "    echo \"Test ground truth already exists, skipping download.\"\n",
    "fi\n",
    "\n",
    "echo \"\\nDataset contents:\"\n",
    "ls -la \"$DATASET_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, sys\n\n# Clone repo from GitHub into Colab's /content (fast, always fresh)\nREPO_DIR = '/content/grapher-nca/M3D-NCA'\nif not os.path.isdir('/content/grapher-nca'):\n    os.system('git clone https://github.com/AvniMittal13/grapher-nca.git /content/grapher-nca')\n\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\n# Install dependencies\nos.system('pip install -q torchio==0.18.82 nibabel tensorboard')\n\nprint(f'Repo dir: {REPO_DIR}')\nprint(f'sys.path OK: {REPO_DIR in sys.path}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.datasets.ISIC_Dataset import ISIC2018_Dataset\n",
    "from src.models.Model_BackboneNCA import BackboneNCA\n",
    "from src.models.Model_GrapherNCA_M1 import GrapherNCA_M1\n",
    "from src.models.Model_GrapherNCA_M2 import GrapherNCA_M2\n",
    "from src.losses.LossFunctions import DiceLoss\n",
    "from src.utils.Experiment import Experiment\n",
    "from src.agents.Agent_Med_NCA import Agent_Med_NCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Experiment\n",
    "\n",
    "Set `model_type` to choose which model to train: `'b1'`, `'m1'`, or `'m2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model type: 'b1' (BackboneNCA), 'm1' (Pixel-Grapher), 'm2' (Patch-Grapher)\n",
    "model_type = 'm1'\n",
    "\n",
    "config = [{\n",
    "    'img_path': os.path.join(DATASET_DIR, 'ISIC2018_Task1-2_Training_Input'),\n",
    "    'label_path': os.path.join(DATASET_DIR, 'ISIC2018_Task1_Training_GroundTruth'),\n",
    "    'model_path': os.path.join(MODELS_DIR, f'GrapherNCA_single_{model_type}'),\n",
    "    'device': 'cuda:0',\n",
    "    'unlock_CPU': True,\n",
    "    # Optimizer\n",
    "    'lr': 1e-4,\n",
    "    'lr_gamma': 0.9999,\n",
    "    'betas': (0.5, 0.5),\n",
    "    # Training\n",
    "    'save_interval': 10,\n",
    "    'evaluate_interval': 10,\n",
    "    'n_epoch': 1000,\n",
    "    'batch_size': 8,\n",
    "    # Model\n",
    "    'channel_n': 64,\n",
    "    'inference_steps': 10,\n",
    "    'cell_fire_rate': 0.5,\n",
    "    'input_channels': 3,  # RGB for ISIC\n",
    "    'output_channels': 1,\n",
    "    'hidden_size': 512,\n",
    "    'train_model': 0,  # Single level\n",
    "    # Data\n",
    "    'input_size': [(256, 256)],\n",
    "    'data_split': [0.7, 0, 0.3],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Choose Architecture and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ISIC2018_Dataset(input_channels=config[0]['input_channels'])\n",
    "device = torch.device(config[0]['device'])\n",
    "\n",
    "# Create model based on model_type\n",
    "if model_type == 'b1':\n",
    "    ca = BackboneNCA(\n",
    "        config[0]['channel_n'], config[0]['cell_fire_rate'], device,\n",
    "        hidden_size=config[0]['hidden_size'], input_channels=config[0]['input_channels']\n",
    "    ).to(device)\n",
    "elif model_type == 'm1':\n",
    "    ca = GrapherNCA_M1(\n",
    "        config[0]['channel_n'], config[0]['cell_fire_rate'], device,\n",
    "        hidden_size=config[0]['hidden_size'], input_channels=config[0]['input_channels'],\n",
    "        k=9\n",
    "    ).to(device)\n",
    "elif model_type == 'm2':\n",
    "    ca = GrapherNCA_M2(\n",
    "        config[0]['channel_n'], config[0]['cell_fire_rate'], device,\n",
    "        hidden_size=config[0]['hidden_size'], input_channels=config[0]['input_channels'],\n",
    "        k=9, patch_size=4\n",
    "    ).to(device)\n",
    "\n",
    "ca = [ca]  # Single level, wrapped in list for Agent_Med_NCA\n",
    "agent = Agent_Med_NCA(ca)\n",
    "exp = Experiment(config, dataset, ca, agent)\n",
    "dataset.set_experiment(exp)\n",
    "exp.set_model_state('train')\n",
    "data_loader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=exp.get_from_config('batch_size'))\n",
    "\n",
    "loss_function = DiceLoss()\n",
    "\n",
    "# Print model parameter count\n",
    "total_params = sum(p.numel() for p in ca[0].parameters())\n",
    "print(f'Model type: {model_type}, Total parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train(data_loader, loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.getAverageDiceScore(pseudo_ensemble=True, showResults=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}